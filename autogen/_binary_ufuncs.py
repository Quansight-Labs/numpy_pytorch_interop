# this file is autogenerated via gen_ufuncs.py
# do not edit manually!

import torch

import _util
from _ndarray import asarray_replacer_1



def add(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.add(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def arctan2(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.arctan2(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def bitwise_and(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.bitwise_and(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def bitwise_or(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.bitwise_or(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def bitwise_xor(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.bitwise_xor(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def copysign(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.copysign(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def divide(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.divide(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def equal(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.eq(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def float_power(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.float_power(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def floor_divide(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.floor_divide(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def fmax(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.fmax(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def fmin(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.fmin(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def fmod(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.fmod(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def gcd(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.gcd(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def greater(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.greater(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def greater_equal(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.greater_equal(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def heaviside(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.heaviside(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def hypot(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.hypot(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def lcm(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.lcm(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def ldexp(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.ldexp(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def left_shift(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.left_shift(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def less(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.less(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def less_equal(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.less_equal(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def logaddexp(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.logaddexp(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def logaddexp2(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.logaddexp2(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def logical_and(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.logical_and(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def logical_or(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.logical_or(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def logical_xor(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.logical_xor(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def matmul(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.matmul(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def maximum(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.maximum(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def minimum(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.minimum(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def remainder(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.remainder(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def multiply(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.multiply(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def nextafter(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.nextafter(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def not_equal(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.not_equal(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def power(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.pow(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def remainder(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.remainder(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def right_shift(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.right_shift(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def subtract(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.subtract(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result



def divide(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K',
            dtype=None, subok=False, **kwds):
    _util.subok_not_ok(subok=subok)
    if order != 'K' or casting != 'same_kind' or not where:
        raise NotImplementedError
    if out is not None:
        # XXX: dtypes, casting
        out = out.to(dtype)
    result = torch.divide(torch.as_tensor(x1), torch.as_tensor(x2), out=out)
    if dtype is not None:
        result = result.to(dtype)
    return result

